{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cultural-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-aaron",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finite-stevens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a structured self-attentive senctence embedding.pdf\n",
      "pre_process.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guided-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/rainism/Desktop/grad/paper_to_code/data/NLP/prefix/nonbreaking_prefix.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    non_breaking_prefix_en = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prerequisite-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetPattern = r\"/Users/rainism/Desktop/grad/paper_to_code/data/NLP/pos/*.txt\"\n",
    "PATH = glob.glob(targetPattern)\n",
    "ls = []\n",
    "\n",
    "for i in PATH:\n",
    "    with open(i,\n",
    "              mode='r',\n",
    "              encoding='utf-8') as f:\n",
    "        ls.append(f.read())\n",
    "        \n",
    "        \n",
    "targetPattern = r\"/Users/rainism/Desktop/grad/paper_to_code/data/NLP/neg/*.txt\"\n",
    "PATH_neg = glob.glob(targetPattern)\n",
    "\n",
    "for i in PATH_neg:\n",
    "    with open(i,\n",
    "              mode='r',\n",
    "              encoding='utf-8') as f:\n",
    "        ls.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
    "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add $$$ after non ending sentence points\n",
    "for prefix in non_breaking_prefix_en:\n",
    "    for idx, corpus_en in enumerate(ls):\n",
    "        corpus_en = corpus_en.replace(prefix, prefix + '$$$')\n",
    "        ls[idx] = corpus_en\n",
    "        \n",
    "for idx, corpus_en in enumerate(ls):\n",
    "    corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en) # ? means that weather it contains something such as [0-9],,,\n",
    "    # # Remove $$$ markers\n",
    "    corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
    "    # # Clear multiple spaces\n",
    "    corpus_en = re.sub(r\"  +\", \" \", corpus_en) # 스페이스 두개 이상(+) 일 경우, 공백 한개로 바꾼다.\n",
    "    corpus_en = corpus_en.split('\\n')\n",
    "    ls[idx] = corpus_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rental-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(ls):\n",
    "    ls[idx] = \"\".join(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unable-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "significant-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "#     flat_list, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opening-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # = 8190 # 여기에 2개를 넣는 이유는, <sos> , <eos> 이 들어갈거기 때문이다(?)\n",
    "# inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]   # tokenizer_en.encode 하는게 sentence_to_token이네 // 하나 이해가 안가는것은, vocab_size_en -2 와 vocab_size_en-1을 왜하는지???\n",
    "#           for sentence in ls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-sally",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "compressed-printing",
   "metadata": {},
   "source": [
    "## tokenizer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recovered-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guided-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {}\n",
    "EMBEDDING_DIM = 100\n",
    "with open(os.path.join(r'/Users/rainism/Desktop/grad/paper_to_code/data/NLP/embedding/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word2vec[values[0]] = values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "detailed-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.038194', '-0.24487', '0.72812', '-0.39961']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['the'][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-burden",
   "metadata": {},
   "source": [
    "## empty embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exclusive-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mexican-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "correct-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrics = np.zeros((NUM_WORDS, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "great-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "    if i < NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrics[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "plastic-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "classified-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    NUM_WORDS,\n",
    "    EMBEDDING_DIM,\n",
    "    weights = [embedding_matrics],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-quick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "downtown-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = tf.ragged.constant(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "handled-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2000, None])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "naughty-manor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 1), dtype=float32, numpy=\n",
       "array([[[ 2.0299904 ],\n",
       "        [-0.83025885]],\n",
       "\n",
       "       [[ 0.93912446],\n",
       "        [-0.63245714]],\n",
       "\n",
       "       [[ 0.9670171 ],\n",
       "        [-2.370026  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([1,2,3])\n",
    "tf.transpose(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "relevant-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([788, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(queries[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "arbitrary-escape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(100, 200) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(5, 100) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input.to_tensor_7 (InstanceMeth (None, None)         0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    2000000     input.to_tensor_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, None, 100)    80400       embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  (None, None, 100)    80400       embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, None, 200)    0           lstm_16[0][0]                    \n",
      "                                                                 lstm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_2 (TFOpLambda) (None, 100, None)    0           tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.tanh (TFOpLambda)       (None, 100, None)    0           tf.linalg.matmul_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_3 (TFOpLambda) (None, 5, None)      0           tf.math.tanh[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5, None)      0           tf.linalg.matmul_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_4 (TFOpLambda) (None, 5, 200)       0           tf.nn.softmax[0][0]              \n",
      "                                                                 tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1000)         0           tf.linalg.matmul_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           10010       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2)            22          dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,170,832\n",
      "Trainable params: 170,832\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = keras.Input(shape = (None,), ragged=True)\n",
    "x = input_.to_tensor()\n",
    "x = embedding_layer(x)\n",
    "x1 = layers.LSTM(100, return_sequences=True, activation = 'tanh')(x)\n",
    "x2 = layers.LSTM(100, return_sequences=True, activation = 'tanh', go_backwards = True)(x)\n",
    "x = tf.concat([x1,x2], axis = -1) # n * 200\n",
    "# x = tf.transpose(x)\n",
    "\n",
    "\n",
    "\n",
    "Ws1 = tf.Variable(tf.random.normal([100,200]), shape=[100,200]) \n",
    "Ws2 = tf.Variable(tf.random.normal([5,100]), shape = [5,100]) # 5명의 사람\n",
    "x_tanh = tf.nn.tanh(tf.matmul(Ws1, x, transpose_b=True))  # 100 * n\n",
    "                    \n",
    "                    \n",
    "x_tanh = tf.matmul(Ws2, x_tanh) # 5 * n\n",
    "x_softmax = tf.nn.softmax(x_tanh) # 5*n\n",
    "\n",
    "                    \n",
    "x = tf.matmul(x_softmax, x) # 5 * 200\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(10)(x)\n",
    "x = keras.layers.Dense(2)(x)\n",
    "\n",
    "model = keras.Model(input_, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-french",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 3:39 - loss: 4.2301 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    \n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "answer = [1] * 1000 + [0] * 1000\n",
    "answer = keras.utils.to_categorical(answer)\n",
    "# answer = tf.ragged.constant(answer)\n",
    "model.fit(queries, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-wilson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-glance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-supplement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "identical-pastor",
   "metadata": {},
   "source": [
    "# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb#scrollTo=pHls7hQVJlk5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-highlight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-jersey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "undefined-gallery",
   "metadata": {},
   "source": [
    "# BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "dense-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "# BUFFER_SIZE = 20000\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((inputs, answer))\n",
    "# dataset = dataset.cache()\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-asset",
   "metadata": {},
   "source": [
    "# Let's build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "lucky-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class embedding_layer(layers.Layer):\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  vocab_size,\n",
    "#                  d_model):\n",
    "#         super(embedding_layer, self).__init__()\n",
    "        \n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.d_model = d_model\n",
    "        \n",
    "\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         embedding = layers.Embedding(self.vocab_size, self.d_model) \n",
    "#         print(embedding(tf.cast(inputs, dtype = float)).shape)\n",
    "#         return embedding(tf.cast(inputs, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "alpine-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bidirectional_LSTM(layers.Layer):\n",
    "    \n",
    "#     ''' bidirectional lstm을 정의한다. '''\n",
    "    \n",
    "#     def __init__(self, \n",
    "#                  units,\n",
    "#                 vocab_size):\n",
    "#         super(Bidirectional_LSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "#         self.units = units        # let's say it's 50\n",
    "#         self.vocab_size = vocab_size\n",
    "        \n",
    "#     def build(self, input_shape):\n",
    "        \n",
    "#         self.d_model = input_shape[-1] # 100\n",
    "#         self.sequence_length = input_shape[-2]\n",
    "        \n",
    "#         self.embedding = embedding_layer(self.vocab_size, 50)\n",
    "        \n",
    "#         # forward lstm\n",
    "#         self.lstm_1 = layers.LSTM(self.units, return_sequences=True, activation = 'tanh')\n",
    "#         # reverse lstm\n",
    "#         self.lstm_2 = layers.LSTM(self.units, return_sequences=True, activation = 'tanh')\n",
    "    \n",
    "        \n",
    "#     def call(self, inputs, outputs):\n",
    "\n",
    "#         x = self.embedding(inputs)\n",
    "#         print(x.shape)\n",
    "#         x1 = self.lstm_1(x)\n",
    "#         x2 = self.lstm_1(x)\n",
    "#         x = tf.concat([x1,x2], axis = -1)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "announced-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Bidirectional_LSTM(50, VOCAB_SIZE_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ordered-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 50)\n",
      "(1111, 50)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1111, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-d041139edfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1006\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-313-b0b1010de88f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    220\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1111, 50)"
     ]
    }
   ],
   "source": [
    "bi(inputs[0],answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-pavilion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
