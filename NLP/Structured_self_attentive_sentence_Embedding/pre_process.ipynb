{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "working-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-newport",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-dairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a structured self-attentive senctence embedding.pdf\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36membedding\u001b[m\u001b[m/\n",
      "pre_process.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daily-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/rainism/Udemy/NLP-cnn/data/fr-en/nonbreaking_prefix.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    non_breaking_prefix_en = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promising-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetPattern = r\"./data/pos/*.txt\"\n",
    "PATH = glob.glob(targetPattern)\n",
    "ls = []\n",
    "\n",
    "for i in PATH:\n",
    "    with open(i,\n",
    "              mode='r',\n",
    "              encoding='utf-8') as f:\n",
    "        ls.append(f.read())\n",
    "        \n",
    "        \n",
    "targetPattern = r\"./data/neg/*.txt\"\n",
    "PATH_neg = glob.glob(targetPattern)\n",
    "\n",
    "for i in PATH_neg:\n",
    "    with open(i,\n",
    "              mode='r',\n",
    "              encoding='utf-8') as f:\n",
    "        ls.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experimental-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
    "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sustainable-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add $$$ after non ending sentence points\n",
    "for prefix in non_breaking_prefix_en:\n",
    "    for idx, corpus_en in enumerate(ls):\n",
    "        corpus_en = corpus_en.replace(prefix, prefix + '$$$')\n",
    "        ls[idx] = corpus_en\n",
    "        \n",
    "for idx, corpus_en in enumerate(ls):\n",
    "    corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en) # ? means that weather it contains something such as [0-9],,,\n",
    "    # # Remove $$$ markers\n",
    "    corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
    "    # # Clear multiple spaces\n",
    "    corpus_en = re.sub(r\"  +\", \" \", corpus_en) # 스페이스 두개 이상(+) 일 경우, 공백 한개로 바꾼다.\n",
    "    corpus_en = corpus_en.split('\\n')\n",
    "    ls[idx] = corpus_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inner-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(ls):\n",
    "    ls[idx] = \"\".join(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patient-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "duplicate-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "#     flat_list, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tested-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # = 8190 # 여기에 2개를 넣는 이유는, <sos> , <eos> 이 들어갈거기 때문이다(?)\n",
    "# inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]   # tokenizer_en.encode 하는게 sentence_to_token이네 // 하나 이해가 안가는것은, vocab_size_en -2 와 vocab_size_en-1을 왜하는지???\n",
    "#           for sentence in ls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-compromise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worst-narrative",
   "metadata": {},
   "source": [
    "## tokenizer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sticky-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spanish-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {}\n",
    "EMBEDDING_DIM = 100\n",
    "with open(os.path.join(r'/Users/rainism/Desktop/grad/paper_to_code/NLP/Structured_self_attentive_sentence_Embedding/embedding/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word2vec[values[0]] = values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "homeless-aircraft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.038194', '-0.24487', '0.72812', '-0.39961']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec['the'][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-heather",
   "metadata": {},
   "source": [
    "## empty embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quick-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incident-stable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "negative-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrics = np.zeros((NUM_WORDS, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "electronic-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "    if i < NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrics[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acting-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thorough-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    NUM_WORDS,\n",
    "    EMBEDDING_DIM,\n",
    "    weights = [embedding_matrics],\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compliant-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = tf.ragged.constant(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "historic-lawrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2000, None])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "weird-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 1), dtype=float32, numpy=\n",
       "array([[[ 2.0299904 ],\n",
       "        [-0.83025885]],\n",
       "\n",
       "       [[ 0.93912446],\n",
       "        [-0.63245714]],\n",
       "\n",
       "       [[ 0.9670171 ],\n",
       "        [-2.370026  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tf.random.normal([1,2,3])\n",
    "tf.transpose(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eleven-store",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([788, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(queries[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "regular-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(100, 200) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(5, 100) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input.to_tensor (InstanceMethod (None, None)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    2000000     input.to_tensor[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 100)    80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 100)    80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, None, 200)    0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul (TFOpLambda)   (None, 100, None)    0           tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.tanh (TFOpLambda)       (None, 100, None)    0           tf.linalg.matmul[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_1 (TFOpLambda) (None, 5, None)      0           tf.math.tanh[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 5, None)      0           tf.linalg.matmul_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_2 (TFOpLambda) (None, 5, 200)       0           tf.nn.softmax[0][0]              \n",
      "                                                                 tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1000)         0           tf.linalg.matmul_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           10010       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            22          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,170,832\n",
      "Trainable params: 170,832\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = keras.Input(shape = (None,), ragged=True)\n",
    "x = input_.to_tensor()\n",
    "x = embedding_layer(x)\n",
    "x1 = layers.LSTM(100, return_sequences=True, activation = 'tanh')(x)\n",
    "x2 = layers.LSTM(100, return_sequences=True, activation = 'tanh', go_backwards = True)(x)\n",
    "x = tf.concat([x1,x2], axis = -1) # n * 200\n",
    "# x = tf.transpose(x)\n",
    "\n",
    "\n",
    "\n",
    "Ws1 = tf.Variable(tf.random.normal([100,200]), shape=[100,200]) \n",
    "Ws2 = tf.Variable(tf.random.normal([5,100]), shape = [5,100]) # 5명의 사람\n",
    "x_tanh = tf.nn.tanh(tf.matmul(Ws1, x, transpose_b=True))  # 100 * n\n",
    "                    \n",
    "                    \n",
    "x_tanh = tf.matmul(Ws2, x_tanh) # 5 * n\n",
    "x_softmax = tf.nn.softmax(x_tanh) # 5*n\n",
    "\n",
    "                    \n",
    "x = tf.matmul(x_softmax, x) # 5 * 200\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(10)(x)\n",
    "x = keras.layers.Dense(2)(x)\n",
    "\n",
    "model = keras.Model(input_, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stretch-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/63 [..............................] - ETA: 4:39 - loss: 4.2876 - accuracy: 0.4688"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "   Inputs to operation gradients/AddN of type AddN must have the same size and shape.  Input 0: [1303,32,100] != input 1: [1187,32,100]\n\t [[{{node gradients/AddN}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_3825]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-50d6b90e0947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# answer = tf.ragged.constant(answer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:    Inputs to operation gradients/AddN of type AddN must have the same size and shape.  Input 0: [1303,32,100] != input 1: [1187,32,100]\n\t [[{{node gradients/AddN}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_3825]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    \n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "answer = [1] * 1000 + [0] * 1000\n",
    "answer = keras.utils.to_categorical(answer)\n",
    "# answer = tf.ragged.constant(answer)\n",
    "model.fit(queries, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-being",
   "metadata": {},
   "source": [
    "# BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "utility-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "# BUFFER_SIZE = 20000\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((inputs, answer))\n",
    "# dataset = dataset.cache()\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "# dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-advocate",
   "metadata": {},
   "source": [
    "# Let's build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "selective-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class embedding_layer(layers.Layer):\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  vocab_size,\n",
    "#                  d_model):\n",
    "#         super(embedding_layer, self).__init__()\n",
    "        \n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.d_model = d_model\n",
    "        \n",
    "\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         embedding = layers.Embedding(self.vocab_size, self.d_model) \n",
    "#         print(embedding(tf.cast(inputs, dtype = float)).shape)\n",
    "#         return embedding(tf.cast(inputs, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "congressional-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bidirectional_LSTM(layers.Layer):\n",
    "    \n",
    "#     ''' bidirectional lstm을 정의한다. '''\n",
    "    \n",
    "#     def __init__(self, \n",
    "#                  units,\n",
    "#                 vocab_size):\n",
    "#         super(Bidirectional_LSTM, self).__init__()\n",
    "        \n",
    "        \n",
    "#         self.units = units        # let's say it's 50\n",
    "#         self.vocab_size = vocab_size\n",
    "        \n",
    "#     def build(self, input_shape):\n",
    "        \n",
    "#         self.d_model = input_shape[-1] # 100\n",
    "#         self.sequence_length = input_shape[-2]\n",
    "        \n",
    "#         self.embedding = embedding_layer(self.vocab_size, 50)\n",
    "        \n",
    "#         # forward lstm\n",
    "#         self.lstm_1 = layers.LSTM(self.units, return_sequences=True, activation = 'tanh')\n",
    "#         # reverse lstm\n",
    "#         self.lstm_2 = layers.LSTM(self.units, return_sequences=True, activation = 'tanh')\n",
    "    \n",
    "        \n",
    "#     def call(self, inputs, outputs):\n",
    "\n",
    "#         x = self.embedding(inputs)\n",
    "#         print(x.shape)\n",
    "#         x1 = self.lstm_1(x)\n",
    "#         x2 = self.lstm_1(x)\n",
    "#         x = tf.concat([x1,x2], axis = -1)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "collaborative-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Bidirectional_LSTM(50, VOCAB_SIZE_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "precious-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 50)\n",
      "(1111, 50)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1111, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-315-d041139edfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1006\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1007\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-313-b0b1010de88f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    220\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_8 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1111, 50)"
     ]
    }
   ],
   "source": [
    "bi(inputs[0],answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-charger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
